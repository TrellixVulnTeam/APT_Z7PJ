{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train \"by hand\" per DPK notebook3 (w/DPK TG, APT dflt IA)\n",
    "\n",
    "Freeze all artifacts/inputs immediately prior to model.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0528 21:23:00.239159 140534767683392 deprecation_wrapper.py:119] From /home/al/git/APT_aldl/deepnet/open_pose4.py:12: The name tf.keras.initializers.random_normal is deprecated. Please use tf.compat.v1.keras.initializers.random_normal instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your cache is: /dat0/apt/cache0426\n",
      "Your models are: ['dpk']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import importlib\n",
    "\n",
    "import deepposekit as dpk\n",
    "\n",
    "import TrainingGeneratorTFRecord as TGTFR\n",
    "import apt_dpk \n",
    "import run_apt_expts_2 as rae\n",
    "import APT_interface as apt\n",
    "import PoseTools as pt\n",
    "import multiResData as mrd\n",
    "import tfdatagen\n",
    "\n",
    "import time\n",
    "from os.path import expanduser\n",
    "\n",
    "import mpl_toolkits.axes_grid1 as axg1\n",
    "\n",
    "DPK_DSET = '/home/al/git/dpkd/datasets/fly/annotation_data_release.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dat0/venv/env/lib/python3.6/site-packages/h5py/_hl/dataset.py:313: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  \"Use dataset[()] instead.\", H5pyDeprecationWarning)\n",
      "W0528 21:23:01.515201 140534767683392 deprecation.py:323] From /home/al/git/APT_aldl/deepnet/PoseTools.py:913: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    }
   ],
   "source": [
    "# Create a TGTFR with our default imgaug\n",
    "LEAPSTRIPPEDLBL = '/dat0/jrcmirror/groups/branson/bransonlab/apt/experiments/data/leap_dataset_gt_stripped.lbl'\n",
    "EXPNAME = 'val10pct'\n",
    "CACHE = '/dat0/apt/cache'\n",
    "RNGSEED = 17\n",
    "\n",
    "dg = dpk.DataGenerator(DPK_DSET)\n",
    "\n",
    "conf = apt.create_conf(LEAPSTRIPPEDLBL, 0, EXPNAME, \\\n",
    "                       CACHE, 'dpkfly', quiet=False)\n",
    "conf.img_dim = 1  # hack, the leap stripped lbl has NumChans=3, but we created the tfr \n",
    "                  # directly using the dpk h5 which is 1-channel\n",
    "conf = apt_dpk.update_conf_dpk(conf,\n",
    "                               dg.graph,\n",
    "                               dg.swap_index,\n",
    "                               n_keypoints=dg.n_keypoints,\n",
    "                               imshape=dg.compute_image_shape(),\n",
    "                               useimgaug=True,\n",
    "                               imgaugtype='dpkfly')\n",
    "tgtfr = TGTFR.TrainingGeneratorTFRecord(conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgtfr.conf.dpk_augmenter.reseed(RNGSEED)\n",
    "tgtfr.use_tfdata = False\n",
    "gtf = tgtfr(n_outputs=1, batch_size=8, \n",
    "       validation=False, confidence=True, shuffle=False)\n",
    "\n",
    "imstgts_apt = [next(gtf) for _ in range(3)]\n",
    "\n",
    "imsapt, tgtsapt = tfdatagen.xylist2xyarr(imstgts_apt, xisscalarlist=True)\n",
    "imsapt.shape, tgtsapt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgtfr.conf.dpk_augmenter.reseed(RNGSEED)\n",
    "tgtfr.use_tfdata = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tgtfr(n_outputs=2, batch_size=8, \n",
    "       validation=False, confidence=True, shuffle=False)\n",
    "\n",
    "imstgts_ds = tfdatagen.read_ds_idxed(ds, range(3))\n",
    "\n",
    "imsDS, tgtsDS = tfdatagen.xylist2xyarr(imstgts_ds)\n",
    "imsDS.shape, tgtsDS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(imsDS,imsapt), np.allclose(tgtsDS,tgtsapt), \\\n",
    "np.array_equal(imsDS,imsapt), np.array_equal(tgtsDS,tgtsapt), \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "dg = dpk.DataGenerator(DPK_DSET)\n",
    "ia = apt_dpk.make_imgaug_augmenter('dpkfly', dg)\n",
    "DSFAC = 2\n",
    "SIGMA = 5\n",
    "VALSPLIT = 0.0\n",
    "GRAPHSCALE = 1\n",
    "tg = dpk.TrainingGenerator(generator=dg,\n",
    "                           downsample_factor=DSFAC,\n",
    "                           augmenter=ia,\n",
    "                           use_graph=True,\n",
    "                           shuffle=True,\n",
    "                           sigma=SIGMA,\n",
    "                           validation_split=VALSPLIT,\n",
    "                           graph_scale=GRAPHSCALE,\n",
    "                           random_seed=0)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgtfr.use_tfdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0528 21:23:49.099966 140534767683392 deprecation.py:506] From /dat0/venv/env/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0528 21:23:59.782961 140534767683392 deprecation.py:323] From /dat0/venv/env/lib/python3.6/site-packages/tensorflow/python/keras/backend.py:4075: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "sdn = dpk.models.StackedDenseNet(tgtfr, \n",
    "                                 n_stacks=2, \n",
    "                                 growth_rate=48, \n",
    "                                 pretrained=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/dat0/apt/cache/leap_dset/dpkfly/view_0/val10pct'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf.cachedir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbk_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", \n",
    "                                              factor=0.2, \n",
    "                                              verbose=1, \n",
    "                                              patience=20)\n",
    "\n",
    "cbk_mdlcpt = tf.keras.callbacks.ModelCheckpoint(\n",
    "    conf.cachedir + \"/best_model_sdn.h5\",\n",
    "    monitor=\"val_loss\",  # monitor=\"loss\" # use if validation_split=0\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "#early_stop = EarlyStopping(\n",
    "#    monitor=\"val_loss\",\n",
    "#    # monitor=\"loss\" # use if validation_split=0\n",
    "#    min_delta=0.001,\n",
    "#    patience=100,\n",
    "#    verbose=1\n",
    "#)\n",
    "\n",
    "callbacks = [cbk_lr, cbk_mdlcpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?tf.keras.Model.fit_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?tf.keras.Model.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BSIZE = 8\n",
    "DLSTEPS = 40000\n",
    "STEPSPEREPOCH = 50\n",
    "EPOCHS = DLSTEPS//STEPSPEREPOCH\n",
    "VALSTEPS = 0  # we aren't using val for anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdn.n_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0528 21:31:46.701739 140534767683392 TrainingGeneratorTFRecord.py:255] Ignoring batch specification of 8, conf batchsize is 8\n",
      "W0528 21:31:46.729755 140534767683392 deprecation_wrapper.py:119] From /home/al/git/APT_aldl/deepnet/tfdatagen.py:666: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\n",
      "W0528 21:31:46.730829 140534767683392 deprecation_wrapper.py:119] From /home/al/git/APT_aldl/deepnet/tfdatagen.py:668: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n",
      "W0528 21:31:46.755593 140534767683392 deprecation.py:323] From /home/al/git/APT_aldl/deepnet/tfdatagen.py:733: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "dstrn = sdn.train_generator(sdn.n_outputs,8,\n",
    "                            validation=False,\n",
    "                            confidence=True,\n",
    "                            shuffle=True,\n",
    "                            infinite=True)\n",
    "                            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resTrn=tfdatagen.read_ds_idxed(dstrn,range(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0528 21:32:02.426002 140534767683392 TrainingGeneratorTFRecord.py:255] Ignoring batch specification of 8, conf batchsize is 8\n"
     ]
    }
   ],
   "source": [
    "dsval = sdn.train_generator(sdn.n_outputs,8,\n",
    "                            validation=True,\n",
    "                            confidence=True,\n",
    "                            shuffle=False,\n",
    "                            infinite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "sdn.fit(\n",
    "    batch_size=BSIZE, #    validation_batch_size=BSIZE,\n",
    "    callbacks=callbacks,\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=STEPSPEREPOCH, #    validation_steps=VALSTEPS,\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.callbacks.ReduceLROnPlateau at 0x7fcf807d8b00>,\n",
       " <tensorflow.python.keras.callbacks.ModelCheckpoint at 0x7fcf30556ef0>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdn.activate_callbacks(callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=sdn.train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.compile('adam','mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/5 [=======================>......] - ETA: 3s - loss: 607.9573 - output_0_loss: 210.4793 - output_1_loss: 202.2973 - output_2_loss: 195.1808\n",
      "Epoch 00001: val_loss improved from inf to 555.67422, saving model to /dat0/apt/cache/leap_dset/dpkfly/view_0/val10pct/best_model_sdn.h5\n",
      "5/5 [==============================] - 55s 11s/step - loss: 598.1797 - output_0_loss: 209.7921 - output_1_loss: 199.1656 - output_2_loss: 189.2220 - val_loss: 555.6742 - val_output_0_loss: 206.0405 - val_output_1_loss: 187.4090 - val_output_2_loss: 162.2247\n",
      "Epoch 2/10\n",
      "4/5 [=======================>......] - ETA: 2s - loss: 510.0365 - output_0_loss: 201.7024 - output_1_loss: 167.8675 - output_2_loss: 140.4666\n",
      "Epoch 00002: val_loss improved from 555.67422 to 517.61894, saving model to /dat0/apt/cache/leap_dset/dpkfly/view_0/val10pct/best_model_sdn.h5\n",
      "5/5 [==============================] - 33s 7s/step - loss: 507.0612 - output_0_loss: 201.7843 - output_1_loss: 165.1151 - output_2_loss: 140.1619 - val_loss: 517.6189 - val_output_0_loss: 203.0757 - val_output_1_loss: 161.3014 - val_output_2_loss: 153.2419\n",
      "Epoch 3/10\n",
      "4/5 [=======================>......] - ETA: 2s - loss: 434.6251 - output_0_loss: 192.6837 - output_1_loss: 125.9755 - output_2_loss: 115.9660\n",
      "Epoch 00003: val_loss did not improve from 517.61894\n",
      "5/5 [==============================] - 32s 6s/step - loss: 433.8838 - output_0_loss: 193.2502 - output_1_loss: 124.5193 - output_2_loss: 116.1144 - val_loss: 523.1836 - val_output_0_loss: 201.3168 - val_output_1_loss: 156.1273 - val_output_2_loss: 165.7395\n",
      "Epoch 4/10\n",
      "4/5 [=======================>......] - ETA: 2s - loss: 406.0589 - output_0_loss: 187.6447 - output_1_loss: 110.4458 - output_2_loss: 107.9684\n",
      "Epoch 00004: val_loss did not improve from 517.61894\n",
      "5/5 [==============================] - 32s 6s/step - loss: 404.0033 - output_0_loss: 185.9822 - output_1_loss: 110.3138 - output_2_loss: 107.7073 - val_loss: 520.1267 - val_output_0_loss: 198.5654 - val_output_1_loss: 159.9230 - val_output_2_loss: 161.6384\n",
      "Epoch 5/10\n",
      "4/5 [=======================>......] - ETA: 1s - loss: 378.6913 - output_0_loss: 174.1331 - output_1_loss: 103.1022 - output_2_loss: 101.4559\n",
      "Epoch 00005: val_loss improved from 517.61894 to 460.46979, saving model to /dat0/apt/cache/leap_dset/dpkfly/view_0/val10pct/best_model_sdn.h5\n",
      "5/5 [==============================] - 33s 7s/step - loss: 378.6642 - output_0_loss: 173.9552 - output_1_loss: 103.2064 - output_2_loss: 101.5026 - val_loss: 460.4698 - val_output_0_loss: 191.7030 - val_output_1_loss: 133.8539 - val_output_2_loss: 134.9129\n",
      "Epoch 6/10\n",
      "4/5 [=======================>......] - ETA: 1s - loss: 372.8304 - output_0_loss: 170.1315 - output_1_loss: 102.2813 - output_2_loss: 100.4176\n",
      "Epoch 00006: val_loss improved from 460.46979 to 421.43404, saving model to /dat0/apt/cache/leap_dset/dpkfly/view_0/val10pct/best_model_sdn.h5\n",
      "5/5 [==============================] - 33s 7s/step - loss: 372.8238 - output_0_loss: 168.9381 - output_1_loss: 102.7577 - output_2_loss: 101.1280 - val_loss: 421.4340 - val_output_0_loss: 183.6290 - val_output_1_loss: 117.9185 - val_output_2_loss: 119.8865\n",
      "Epoch 7/10\n",
      "4/5 [=======================>......] - ETA: 1s - loss: 372.5155 - output_0_loss: 166.0510 - output_1_loss: 103.8472 - output_2_loss: 102.6173\n",
      "Epoch 00007: val_loss did not improve from 421.43404\n",
      "5/5 [==============================] - 33s 7s/step - loss: 370.9540 - output_0_loss: 166.0885 - output_1_loss: 102.9986 - output_2_loss: 101.8668 - val_loss: 446.0497 - val_output_0_loss: 185.0933 - val_output_1_loss: 132.1586 - val_output_2_loss: 128.7977\n",
      "Epoch 8/10\n",
      "4/5 [=======================>......] - ETA: 1s - loss: 349.8071 - output_0_loss: 159.0893 - output_1_loss: 95.7801 - output_2_loss: 94.9377\n",
      "Epoch 00008: val_loss improved from 421.43404 to 412.51578, saving model to /dat0/apt/cache/leap_dset/dpkfly/view_0/val10pct/best_model_sdn.h5\n",
      "5/5 [==============================] - 33s 7s/step - loss: 348.0060 - output_0_loss: 157.8002 - output_1_loss: 95.5358 - output_2_loss: 94.6701 - val_loss: 412.5158 - val_output_0_loss: 174.2791 - val_output_1_loss: 119.5683 - val_output_2_loss: 118.6683\n",
      "Epoch 9/10\n",
      "4/5 [=======================>......] - ETA: 1s - loss: 345.0237 - output_0_loss: 148.2810 - output_1_loss: 98.8202 - output_2_loss: 97.9226\n",
      "Epoch 00009: val_loss improved from 412.51578 to 385.43239, saving model to /dat0/apt/cache/leap_dset/dpkfly/view_0/val10pct/best_model_sdn.h5\n",
      "5/5 [==============================] - 33s 7s/step - loss: 343.2697 - output_0_loss: 147.7581 - output_1_loss: 98.1499 - output_2_loss: 97.3616 - val_loss: 385.4324 - val_output_0_loss: 164.9803 - val_output_1_loss: 110.0921 - val_output_2_loss: 110.3600\n",
      "Epoch 10/10\n",
      "4/5 [=======================>......] - ETA: 1s - loss: 331.3058 - output_0_loss: 140.6299 - output_1_loss: 95.6240 - output_2_loss: 95.0518\n",
      "Epoch 00010: val_loss improved from 385.43239 to 368.27778, saving model to /dat0/apt/cache/leap_dset/dpkfly/view_0/val10pct/best_model_sdn.h5\n",
      "5/5 [==============================] - 33s 7s/step - loss: 333.2424 - output_0_loss: 141.3330 - output_1_loss: 96.2824 - output_2_loss: 95.6270 - val_loss: 368.2778 - val_output_0_loss: 155.5701 - val_output_1_loss: 106.8839 - val_output_2_loss: 105.8238\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcee3bf7fd0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(dstrn,\n",
    "      epochs=10,\n",
    "      steps_per_epoch=5,\n",
    "      verbose=1,\n",
    "      callbacks=callbacks,\n",
    "      validation_data=dsval,\n",
    "      validation_steps=int(np.ceil(150/8)) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1350/8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train with APT using dflt IA. \n",
    "\n",
    "Freeze all artifacts/inputs. Compare results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train with APT using PT and Bub aug params.\n",
    "Freeze all artifacts/inputs. Compare results.\n",
    "(TODO: add this to data_pipeline nb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
