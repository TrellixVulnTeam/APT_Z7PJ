{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train apt/dpk test valdist cbk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import importlib\n",
    "\n",
    "import deepposekit as dpk\n",
    "\n",
    "import TrainingGeneratorTFRecord as TGTFR\n",
    "import apt_dpk \n",
    "import run_apt_expts_2 as rae\n",
    "import APT_interface as apt\n",
    "import PoseTools as pt\n",
    "import multiResData as mrd\n",
    "import tfdatagen\n",
    "import apt_dpk_exps as ade\n",
    "\n",
    "import time\n",
    "from os.path import expanduser\n",
    "\n",
    "import mpl_toolkits.axes_grid1 as axg1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expname = '/dat0/apt/cache/leap_dset/dpkfly/view_0/dpkorig_20200512T180752_run4_tfr_ptia_01_TEST'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ade.exp2orig_train(expname, shortdebugrun=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picf='/dat0/apt/cache/leap_dset/dpkfly/view_0/dpkorig_20200512T180752_run4_tfr_ptia_01_TEST/trn20200614T101737.vdist.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic=pt.pickle_load(picf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in pic.items():\n",
    "    print(\"{}: {}\".format(k, len(v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/dat0/apt/dpkwking/dumba.foo.log','a') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['asd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TGTFR with our default imgaug\n",
    "LEAPSTRIPPEDLBL = '/dat0/jrcmirror/groups/branson/bransonlab/apt/experiments/data/leap_dataset_gt_stripped.lbl'\n",
    "EXPNAME = 'val10pct'\n",
    "CACHE = '/dat0/apt/cache'\n",
    "RNGSEED = 17\n",
    "\n",
    "dg = dpk.DataGenerator(DPK_DSET)\n",
    "\n",
    "conf = apt.create_conf(LEAPSTRIPPEDLBL, 0, EXPNAME, \\\n",
    "                       CACHE, 'dpkfly', quiet=False)\n",
    "conf.img_dim = 1  # hack, the leap stripped lbl has NumChans=3, but we created the tfr \n",
    "                  # directly using the dpk h5 which is 1-channel\n",
    "conf = apt_dpk.update_conf_dpk(conf,\n",
    "                               dg.graph,\n",
    "                               dg.swap_index,\n",
    "                               n_keypoints=dg.n_keypoints,\n",
    "                               imshape=dg.compute_image_shape(),\n",
    "                               useimgaug=True,\n",
    "                               imgaugtype='dpkfly')\n",
    "tgtfr = TGTFR.TrainingGeneratorTFRecord(conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgtfr.conf.dpk_augmenter.reseed(RNGSEED)\n",
    "tgtfr.use_tfdata = False\n",
    "gtf = tgtfr(n_outputs=1, batch_size=8, \n",
    "       validation=False, confidence=True, shuffle=False)\n",
    "\n",
    "imstgts_apt = [next(gtf) for _ in range(3)]\n",
    "\n",
    "imsapt, tgtsapt = tfdatagen.xylist2xyarr(imstgts_apt, xisscalarlist=True)\n",
    "imsapt.shape, tgtsapt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgtfr.conf.dpk_augmenter.reseed(RNGSEED)\n",
    "tgtfr.use_tfdata = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tgtfr(n_outputs=2, batch_size=8, \n",
    "       validation=False, confidence=True, shuffle=False)\n",
    "\n",
    "imstgts_ds = tfdatagen.read_ds_idxed(ds, range(3))\n",
    "\n",
    "imsDS, tgtsDS = tfdatagen.xylist2xyarr(imstgts_ds)\n",
    "imsDS.shape, tgtsDS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(imsDS,imsapt), np.allclose(tgtsDS,tgtsapt), \\\n",
    "np.array_equal(imsDS,imsapt), np.array_equal(tgtsDS,tgtsapt), \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "dg = dpk.DataGenerator(DPK_DSET)\n",
    "ia = apt_dpk.make_imgaug_augmenter('dpkfly', dg)\n",
    "DSFAC = 2\n",
    "SIGMA = 5\n",
    "VALSPLIT = 0.0\n",
    "GRAPHSCALE = 1\n",
    "tg = dpk.TrainingGenerator(generator=dg,\n",
    "                           downsample_factor=DSFAC,\n",
    "                           augmenter=ia,\n",
    "                           use_graph=True,\n",
    "                           shuffle=True,\n",
    "                           sigma=SIGMA,\n",
    "                           validation_split=VALSPLIT,\n",
    "                           graph_scale=GRAPHSCALE,\n",
    "                           random_seed=0)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgtfr.use_tfdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdn = dpk.models.StackedDenseNet(tgtfr, \n",
    "                                 n_stacks=2, \n",
    "                                 growth_rate=48, \n",
    "                                 pretrained=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf.cachedir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbk_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", \n",
    "                                              factor=0.2, \n",
    "                                              verbose=1, \n",
    "                                              patience=20)\n",
    "\n",
    "cbk_mdlcpt = tf.keras.callbacks.ModelCheckpoint(\n",
    "    conf.cachedir + \"/best_model_sdn.h5\",\n",
    "    monitor=\"val_loss\",  # monitor=\"loss\" # use if validation_split=0\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "#early_stop = EarlyStopping(\n",
    "#    monitor=\"val_loss\",\n",
    "#    # monitor=\"loss\" # use if validation_split=0\n",
    "#    min_delta=0.001,\n",
    "#    patience=100,\n",
    "#    verbose=1\n",
    "#)\n",
    "\n",
    "callbacks = [cbk_lr, cbk_mdlcpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?tf.keras.Model.fit_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?tf.keras.Model.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BSIZE = 8\n",
    "DLSTEPS = 40000\n",
    "STEPSPEREPOCH = 50\n",
    "EPOCHS = DLSTEPS//STEPSPEREPOCH\n",
    "VALSTEPS = 0  # we aren't using val for anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdn.n_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstrn = sdn.train_generator(sdn.n_outputs,8,\n",
    "                            validation=False,\n",
    "                            confidence=True,\n",
    "                            shuffle=True,\n",
    "                            infinite=True)\n",
    "                            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resTrn=tfdatagen.read_ds_idxed(dstrn,range(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsval = sdn.train_generator(sdn.n_outputs,8,\n",
    "                            validation=True,\n",
    "                            confidence=True,\n",
    "                            shuffle=False,\n",
    "                            infinite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "sdn.fit(\n",
    "    batch_size=BSIZE, #    validation_batch_size=BSIZE,\n",
    "    callbacks=callbacks,\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=STEPSPEREPOCH, #    validation_steps=VALSTEPS,\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdn.activate_callbacks(callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=sdn.train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.compile('adam','mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.fit(dstrn,\n",
    "      epochs=10,\n",
    "      steps_per_epoch=5,\n",
    "      verbose=1,\n",
    "      callbacks=callbacks,\n",
    "      validation_data=dsval,\n",
    "      validation_steps=int(np.ceil(150/8)) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1350/8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train with APT using dflt IA. \n",
    "\n",
    "Freeze all artifacts/inputs. Compare results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train with APT using PT and Bub aug params.\n",
    "Freeze all artifacts/inputs. Compare results.\n",
    "(TODO: add this to data_pipeline nb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
