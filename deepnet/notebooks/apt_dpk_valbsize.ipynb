{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0605 10:58:48.588803 140289466017600 deprecation_wrapper.py:119] From /home/al/git/APT_aldl/deepnet/open_pose4.py:12: The name tf.keras.initializers.random_normal is deprecated. Please use tf.compat.v1.keras.initializers.random_normal instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your cache is: /dat0/apt/cache0426\n",
      "Your models are: ['dpk']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "import deepposekit as dpk\n",
    "\n",
    "import TrainingGeneratorTFRecord as TGTFR\n",
    "import apt_dpk \n",
    "import run_apt_expts_2 as rae\n",
    "import APT_interface as apt\n",
    "import PoseTools as pt\n",
    "import multiResData as mrd\n",
    "import open_pose_data as opd\n",
    "import util\n",
    "import tfdatagen\n",
    "import apt_dpk_exps as ade\n",
    "\n",
    "import time\n",
    "from os.path import expanduser\n",
    "\n",
    "import mpl_toolkits.axes_grid1 as axg1\n",
    "\n",
    "DPK_DSET = '/home/al/git/dpkd/datasets/fly/annotation_data_release.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "defaultlogger = logging.getLogger()\n",
    "defaultlogger.setLevel(logging.DEBUG)\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter(\"[%(asctime)s] %(levelname)s [%(name)s.%(funcName)s:%(lineno)d] %(message)s\")\n",
    "ch.setFormatter(formatter)\n",
    "for handler in defaultlogger.handlers[:]:\n",
    "    defaultlogger.removeHandler(handler)\n",
    "defaultlogger.addHandler(ch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dat0/venv/env/lib/python3.6/site-packages/h5py/_hl/dataset.py:313: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  \"Use dataset[()] instead.\", H5pyDeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/dat0/apt/cache/leap_dset/dpkfly/view_0/val10pct'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dg = dpk.DataGenerator(DPK_DSET)\n",
    "\n",
    "LEAPSTRIPPEDLBL = '/dat0/jrcmirror/groups/branson/bransonlab/apt/experiments/data/leap_dataset_gt_stripped.lbl'\n",
    "EXPNAME = 'val10pct'\n",
    "CACHE = '/dat0/apt/cache'\n",
    "conf = apt.create_conf(LEAPSTRIPPEDLBL, 0, EXPNAME, \\\n",
    "                       CACHE, 'dpkfly', quiet=False)\n",
    "conf.img_dim = 1  # hack, the leap stripped lbl has NumChans=3, but we created the tfr \n",
    "                  # directly using the dpk h5 which is 1-channel\n",
    "conf.cachedir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-06-05 10:58:53,916] INFO [root.update_conf_dpk:473] DPK size stuff: imsz=(192, 192), imsz_pad=(192, 192), imsz_net=(192, 192), rescale=1.0, n_trans_min=5\n"
     ]
    }
   ],
   "source": [
    "conf = apt_dpk.update_conf_dpk(conf,\n",
    "                               dg.graph,\n",
    "                               dg.swap_index,\n",
    "                               n_keypoints=dg.n_keypoints,\n",
    "                               imshape=dg.compute_image_shape(),\n",
    "                               useimgaug=True,\n",
    "                               imgaugtype='dpkfly')\n",
    "conf.batch_size = 16\n",
    "conf.dpk_use_tfdata = True\n",
    "conf.display_step = 84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars(conf\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCbk(tf.keras.callbacks.Callback):\n",
    "\n",
    "    def on_train_batch_begin(self, bch, logs):\n",
    "        print('otrnbb')\n",
    "        print(bch)\n",
    "        print(logs)\n",
    "    def on_test_batch_begin(self, bch, logs):\n",
    "        print('otstbb')\n",
    "        print(bch)\n",
    "        print(logs)\n",
    "    def on_train_batch_end(self, bch, logs):\n",
    "        print('otrnbe')\n",
    "        print(bch)\n",
    "        print(logs)\n",
    "    def on_test_batch_end(self, bch, logs):\n",
    "        print('otstbe')\n",
    "        print(bch)\n",
    "        print(logs)\n",
    "    def on_epoch_begin(self, epoch, logs):\n",
    "        print('oeb')\n",
    "        print(epoch)\n",
    "        print(logs)\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print('oee')\n",
    "        print(epoch)\n",
    "        print(logs)\n",
    "\n",
    "cbks = [MyCbk()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_generator kwargs: {'verbose': 2}\n",
      "oeb\n",
      "0\n",
      "{}\n",
      "Epoch 1/10\n",
      "otrnbb\n",
      "0\n",
      "{'batch': 0, 'size': 16}\n",
      "otrnbe\n",
      "0\n",
      "{'batch': 0, 'size': 16, 'loss': 635.0797, 'output_0_loss': 210.82149, 'output_1_loss': 212.19814, 'output_2_loss': 212.06012}\n",
      "otrnbb\n",
      "1\n",
      "{'batch': 1, 'size': 16}\n",
      "otrnbe\n",
      "1\n",
      "{'batch': 1, 'size': 16, 'loss': 611.772, 'output_0_loss': 208.77869, 'output_1_loss': 208.41676, 'output_2_loss': 206.2304}\n",
      "otrnbb\n",
      "2\n",
      "{'batch': 2, 'size': 16}\n",
      "otrnbe\n",
      "2\n",
      "{'batch': 2, 'size': 16, 'loss': 601.1177, 'output_0_loss': 208.59438, 'output_1_loss': 205.83836, 'output_2_loss': 201.55705}\n",
      "otstbb\n",
      "0\n",
      "{'batch': 0, 'size': 8}\n",
      "otstbe\n",
      "0\n",
      "{'batch': 0, 'size': 8, 'loss': 582.6643, 'output_0_loss': 204.0145, 'output_1_loss': 194.5859, 'output_2_loss': 184.06392}\n",
      "otstbb\n",
      "1\n",
      "{'batch': 1, 'size': 8}\n",
      "otstbe\n",
      "1\n",
      "{'batch': 1, 'size': 8, 'loss': 596.7048, 'output_0_loss': 206.40002, 'output_1_loss': 196.90883, 'output_2_loss': 186.3757}\n",
      "otstbb\n",
      "2\n",
      "{'batch': 2, 'size': 8}\n",
      "otstbe\n",
      "2\n",
      "{'batch': 2, 'size': 8, 'loss': 590.941, 'output_0_loss': 206.52655, 'output_1_loss': 197.05132, 'output_2_loss': 186.52551}\n",
      "otstbb\n",
      "3\n",
      "{'batch': 3, 'size': 8}\n",
      "otstbe\n",
      "3\n",
      "{'batch': 3, 'size': 8, 'loss': 604.9908, 'output_0_loss': 207.78984, 'output_1_loss': 198.2987, 'output_2_loss': 187.7367}\n",
      "otstbb\n",
      "4\n",
      "{'batch': 4, 'size': 8}\n",
      "otstbe\n",
      "4\n",
      "{'batch': 4, 'size': 8, 'loss': 604.3015, 'output_0_loss': 208.50357, 'output_1_loss': 198.99536, 'output_2_loss': 188.42155}\n",
      "otstbb\n",
      "5\n",
      "{'batch': 5, 'size': 8}\n",
      "otstbe\n",
      "5\n",
      "{'batch': 5, 'size': 8, 'loss': 588.2436, 'output_0_loss': 208.08107, 'output_1_loss': 198.56885, 'output_2_loss': 187.99107}\n",
      "otstbb\n",
      "6\n",
      "{'batch': 6, 'size': 8}\n",
      "otstbe\n",
      "6\n",
      "{'batch': 6, 'size': 8, 'loss': 603.824, 'output_0_loss': 208.52254, 'output_1_loss': 199.00175, 'output_2_loss': 188.42857}\n",
      "otstbb\n",
      "7\n",
      "{'batch': 7, 'size': 8}\n",
      "otstbe\n",
      "7\n",
      "{'batch': 7, 'size': 8, 'loss': 617.95825, 'output_0_loss': 209.45918, 'output_1_loss': 199.91922, 'output_2_loss': 189.32513}\n",
      "otstbb\n",
      "8\n",
      "{'batch': 8, 'size': 8}\n",
      "otstbe\n",
      "8\n",
      "{'batch': 8, 'size': 8, 'loss': 600.05225, 'output_0_loss': 209.51324, 'output_1_loss': 199.96907, 'output_2_loss': 189.37106}\n",
      "otstbb\n",
      "9\n",
      "{'batch': 9, 'size': 8}\n",
      "otstbe\n",
      "9\n",
      "{'batch': 9, 'size': 8, 'loss': 599.796, 'output_0_loss': 209.53989, 'output_1_loss': 199.99763, 'output_2_loss': 189.41013}\n",
      "otstbb\n",
      "10\n",
      "{'batch': 10, 'size': 8}\n",
      "otstbe\n",
      "10\n",
      "{'batch': 10, 'size': 8, 'loss': 581.6426, 'output_0_loss': 209.00153, 'output_1_loss': 199.47256, 'output_2_loss': 188.90038}\n",
      "otstbb\n",
      "11\n",
      "{'batch': 11, 'size': 8}\n",
      "otstbe\n",
      "11\n",
      "{'batch': 11, 'size': 8, 'loss': 612.27124, 'output_0_loss': 209.41771, 'output_1_loss': 199.8827, 'output_2_loss': 189.31543}\n",
      "otstbb\n",
      "12\n",
      "{'batch': 12, 'size': 8}\n",
      "otstbe\n",
      "12\n",
      "{'batch': 12, 'size': 8, 'loss': 579.55286, 'output_0_loss': 208.92221, 'output_1_loss': 199.38988, 'output_2_loss': 188.83739}\n",
      "otstbb\n",
      "13\n",
      "{'batch': 13, 'size': 8}\n",
      "otstbe\n",
      "13\n",
      "{'batch': 13, 'size': 8, 'loss': 601.1842, 'output_0_loss': 209.01894, 'output_1_loss': 199.48233, 'output_2_loss': 188.9364}\n",
      "otstbb\n",
      "14\n",
      "{'batch': 14, 'size': 8}\n",
      "otstbe\n",
      "14\n",
      "{'batch': 14, 'size': 8, 'loss': 583.6254, 'output_0_loss': 208.7141, 'output_1_loss': 199.17485, 'output_2_loss': 188.62791}\n",
      "otstbb\n",
      "15\n",
      "{'batch': 15, 'size': 8}\n",
      "otstbe\n",
      "15\n",
      "{'batch': 15, 'size': 8, 'loss': 598.47565, 'output_0_loss': 208.75644, 'output_1_loss': 199.21808, 'output_2_loss': 188.66476}\n",
      "otstbb\n",
      "16\n",
      "{'batch': 16, 'size': 8}\n",
      "otstbe\n",
      "16\n",
      "{'batch': 16, 'size': 8, 'loss': 626.0239, 'output_0_loss': 209.3419, 'output_1_loss': 199.79214, 'output_2_loss': 189.23375}\n",
      "otstbb\n",
      "17\n",
      "{'batch': 17, 'size': 8}\n",
      "otstbe\n",
      "17\n",
      "{'batch': 17, 'size': 8, 'loss': 570.83496, 'output_0_loss': 208.82863, 'output_1_loss': 199.28098, 'output_2_loss': 188.72858}\n",
      "oee\n",
      "0\n",
      "{'loss': 615.9897867838541, 'output_0_loss': 208.59438, 'output_1_loss': 205.83836, 'output_2_loss': 201.55705, 'val_loss': 596.8381822374132, 'val_output_0_loss': 208.82863, 'val_output_1_loss': 199.28098, 'val_output_2_loss': 188.72858}\n",
      "3/3 - 39s - loss: 615.9898 - output_0_loss: 208.5944 - output_1_loss: 205.8384 - output_2_loss: 201.5571 - val_loss: 596.8382 - val_output_0_loss: 208.8286 - val_output_1_loss: 199.2810 - val_output_2_loss: 188.7286\n",
      "oeb\n",
      "1\n",
      "{}\n",
      "Epoch 2/10\n",
      "otrnbb\n",
      "0\n",
      "{'batch': 0, 'size': 16}\n",
      "otrnbe\n",
      "0\n",
      "{'batch': 0, 'size': 16, 'loss': 570.24316, 'output_0_loss': 203.69116, 'output_1_loss': 189.94556, 'output_2_loss': 176.60643}\n",
      "otrnbb\n",
      "1\n",
      "{'batch': 1, 'size': 16}\n",
      "otrnbe\n",
      "1\n",
      "{'batch': 1, 'size': 16, 'loss': 544.7199, 'output_0_loss': 202.787, 'output_1_loss': 184.92987, 'output_2_loss': 169.76465}\n",
      "otrnbb\n",
      "2\n",
      "{'batch': 2, 'size': 16}\n",
      "otrnbe\n",
      "2\n",
      "{'batch': 2, 'size': 16, 'loss': 525.1764, 'output_0_loss': 203.06274, 'output_1_loss': 180.292, 'output_2_loss': 163.3584}\n",
      "otstbb\n",
      "0\n",
      "{'batch': 0, 'size': 8}\n",
      "otstbe\n",
      "0\n",
      "{'batch': 0, 'size': 8, 'loss': 528.9475, 'output_0_loss': 207.57074, 'output_1_loss': 172.01646, 'output_2_loss': 149.36028}\n",
      "otstbb\n",
      "1\n",
      "{'batch': 1, 'size': 8}\n",
      "otstbe\n",
      "1\n",
      "{'batch': 1, 'size': 8, 'loss': 517.06, 'output_0_loss': 205.35522, 'output_1_loss': 170.09679, 'output_2_loss': 147.55173}\n",
      "otstbb\n",
      "2\n",
      "{'batch': 2, 'size': 8}\n",
      "otstbe\n",
      "2\n",
      "{'batch': 2, 'size': 8, 'loss': 518.5626, 'output_0_loss': 204.74213, 'output_1_loss': 169.62975, 'output_2_loss': 147.15152}\n",
      "otstbb\n",
      "3\n",
      "{'batch': 3, 'size': 8}\n",
      "otstbe\n",
      "3\n",
      "{'batch': 3, 'size': 8, 'loss': 524.9289, 'output_0_loss': 205.24911, 'output_1_loss': 169.8838, 'output_2_loss': 147.24185}\n",
      "otstbb\n",
      "4\n",
      "{'batch': 4, 'size': 8}\n",
      "otstbe\n",
      "4\n",
      "{'batch': 4, 'size': 8, 'loss': 521.1782, 'output_0_loss': 205.32968, 'output_1_loss': 169.78386, 'output_2_loss': 147.02193}\n",
      "otstbb\n",
      "5\n",
      "{'batch': 5, 'size': 8}\n",
      "otstbe\n",
      "5\n",
      "{'batch': 5, 'size': 8, 'loss': 516.04144, 'output_0_loss': 204.97835, 'output_1_loss': 169.45981, 'output_2_loss': 146.68166}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-e1bf45253aaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# validation_steps=VALSTEPS,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     )\n\u001b[1;32m     40\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/al/git/dpk/deepposekit/models/engine.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, batch_size, validation_batch_size, callbacks, epochs, use_multiprocessing, n_workers, steps_per_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mactivated_callbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         )\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dat0/venv/env/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1431\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1433\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m/dat0/venv/env/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    320\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m           \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m           steps_name='validation_steps')\n\u001b[0m\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dat0/venv/env/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtarget_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m       \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dat0/venv/env/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36m_get_next_batch\u001b[0;34m(generator, mode)\u001b[0m\n\u001b[1;32m    360\u001b[0m   \u001b[0;34m\"\"\"Retrieves the next batch of input data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dat0/venv/env/lib/python3.6/site-packages/tensorflow/python/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    777\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "USEDG = True\n",
    "\n",
    "if USEDG:\n",
    "    VALSPLIT = 0.1\n",
    "    assert conf.dpk_downsample_factor == 2\n",
    "    assert conf.dpk_input_sigma == 5.0\n",
    "    assert conf.dpk_graph_scale == 1.0\n",
    "    tg = dpk.TrainingGenerator(generator=dg,\n",
    "                               downsample_factor=conf.dpk_downsample_factor,\n",
    "                               augmenter=conf.dpk_augmenter,\n",
    "                               use_graph=True,\n",
    "                               shuffle=True,\n",
    "                               sigma=conf.dpk_input_sigma,\n",
    "                               validation_split=VALSPLIT,\n",
    "                               graph_scale=conf.dpk_graph_scale,\n",
    "                               random_seed=0)\n",
    "    sdn = dpk.models.StackedDenseNet(tg,\n",
    "                                     n_stacks=conf.dpk_n_stacks,\n",
    "                                     growth_rate=conf.dpk_growth_rate,\n",
    "                                     pretrained=True,\n",
    "                                     )\n",
    "    DECAY = 0.0  # LR modulated via callback\n",
    "    assert conf.dpk_base_lr_factory == .001\n",
    "    optimizer = tf.keras.optimizers.Adam(\n",
    "        lr=conf.dpk_base_lr_factory, beta_1=0.9, beta_2=0.999, epsilon=None,\n",
    "        decay=DECAY, amsgrad=False)\n",
    "    sdn.compile(optimizer=optimizer, loss='mse')\n",
    "    \n",
    "    VALBSIZE = 8\n",
    "    EPOCHS = 10\n",
    "    bsize = conf.batch_size\n",
    "    sdn.fit(\n",
    "        batch_size=bsize,\n",
    "        validation_batch_size=VALBSIZE,\n",
    "        callbacks=cbks,\n",
    "        epochs=EPOCHS,\n",
    "        steps_per_epoch=3,  # validation_steps=VALSTEPS,\n",
    "        verbose=2\n",
    "    )\n",
    "else:\n",
    "    tgtfr, sdn = apt_dpk.compile(conf)\n",
    "    #cbks = ade.create_callbacks_exp2orig_train(conf, sdn)\n",
    "\n",
    "    bsize = conf.batch_size\n",
    "    valbsize = 16\n",
    "    dstrn = sdn.train_generator(sdn.n_outputs,\n",
    "                                bsize,\n",
    "                                validation=False,\n",
    "                                confidence=True,\n",
    "                                shuffle=True,\n",
    "                                infinite=True)\n",
    "    dsval = sdn.train_generator(sdn.n_outputs,\n",
    "                                valbsize,\n",
    "                                validation=True,\n",
    "                                confidence=True,\n",
    "                                shuffle=False,\n",
    "                                infinite=False)\n",
    "    #sdn.activate_callbacks(cbks)\n",
    "    \n",
    "\n",
    "    train_model = sdn.train_model\n",
    "\n",
    "    epochs = 100\n",
    "    steps_per_epoch = 3\n",
    "    train_model.fit(dstrn,\n",
    "                    epochs=epochs,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    verbose=1,\n",
    "                    callbacks=cbks,\n",
    "                    validation_data=dsval,\n",
    "                    validation_steps=9,\n",
    "                   )\n",
    "\n",
    "                        \n",
    "# Cached images in strippedlbl differ from dpk h5! \n",
    "# - Ims are 3-chan grayscale vs 1-chan\n",
    "# - Locs are off-by-one; strippedlbl prob correct (0-based)\n",
    "#apt.create_tfrecord(conf,split=False,use_cache=True)\n",
    "\n",
    "\n",
    "# So rather than use apt.create_tfrecord, we create the tfr directly from the h5 even \n",
    "# though it may be off-by-one for replication purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "19*8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model.metrics_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "150//16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgtfr = TGTFR.TrainingGeneratorTFRecord(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdn = dpk.models.StackedDenseNet(tgtfr, \n",
    "                                 n_stacks=2, \n",
    "                                 growth_rate=48, \n",
    "                                 pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(sdn.train_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(tfdatagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsval = tgtfr.get_tfdataset(validation=True, confidence=True, n_outputs=1,\n",
    "                            shuffle=False, infinite=False,\n",
    "                            instrumented=True,instrumentedname='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfdatagen.thecounter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resDSraw = tfdatagen.read_ds_idxed(dsval,range(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(resDSraw)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "    resDSraw[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resDSraw[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfdatagen.thecounter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(dsval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resDSraw[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imsDSraw, locsDSraw, tgtsDSraw = xylist2xyarr(resDSraw)\n",
    "imsDSraw.shape, locsDSraw,shape, tgtsDSraw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "resDS = read_ds_idxed(ds, range(150//4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imsDS, tgtsDS = xylist2xyarr(resDS)\n",
    "imsDS.shape, tgtsDS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgtsDS[-140,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(imsdpk,imsDS,), np.allclose(tgtsdpk, tgtsDS), \\\n",
    "np.array_equal(imsdpk, imsDS), np.array_equal(tgtsdpk, tgtsDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgtsDS[2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imsstk = np.moveaxis(imsDS, 0, -1)\n",
    "imsstk = imsstk[:,:,0,:]\n",
    "imsstk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "montage(imsDS[:10,...],locs=tgtsDS[:10,...],cmap='gray',locsmrkrsz=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tf.keras.Model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpth5 = '/dat0/apt/cache/leap_dset/dpkfly/view_0/val10pct/best_model_sdn.h5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdn = dpk.models.load_model(cpth5, generator=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg = dpk.DataGenerator(DPK_DSET)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
